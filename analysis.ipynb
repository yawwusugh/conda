{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import geopandas\n",
    "from haversine import haversine_vector, Unit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_year = \"2017_2018\"\n",
    "schools_df = geopandas.read_file(\"LCPS_data/LCPS_Sites_%s.shp\" % school_year)\n",
    "spas_df = geopandas.read_file(\"LCPS_data/PlanningZones_%s.shp\" % school_year)\n",
    "students_df = geopandas.read_file(\"LCPS_data/Students_%s.shp\" % school_year)\n",
    "\n",
    "schools_df = schools_df.to_crs(epsg=4326)  # This gives us proper lat and long in the WGS84 ellipsoid.\n",
    "spas_df = spas_df.to_crs(schools_df.crs)\n",
    "students_df = students_df.to_crs(schools_df.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df = schools_df[(schools_df.CLASS == \"ELEMENTARY\") | (schools_df.CLASS == \"MIDDLE\") | (schools_df.CLASS == \"HIGH\")]\n",
    "schools_df = schools_df[(schools_df.NAME != \"DOUGLASS COMMUNITY\") & (schools_df.NAME != \"CS MONROE TECHNOLOGY\")]\n",
    "\n",
    "es_schools_df = schools_df[schools_df.CLASS == \"ELEMENTARY\"]\n",
    "ms_schools_df = schools_df[schools_df.CLASS == \"MIDDLE\"]\n",
    "hs_schools_df = schools_df[schools_df.CLASS == \"HIGH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(range(0, 11))\n",
    "X_S = [\"ES\", \"MS\", \"HS\"]\n",
    "shc_results = dict(zip(X_S, [dict() for S in X_S]))\n",
    "\n",
    "for weight, school_level in itertools.product(weights, X_S):\n",
    "    with open(\"results/SHC/run%d_%s_SHC.json\" % (weight, school_level), \"r\") as results_file:\n",
    "        shc_results[school_level][weight] = json.load(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These 3 lines take ~1 minute on 8 hyperthreads.\n",
    "students_df = students_df[students_df.GRADE != 14]\n",
    "loudoun_polygon = spas_df.unary_union\n",
    "students_df = students_df[students_df.geometry.parallel_map(loudoun_polygon.contains)]\n",
    "\n",
    "es_students_df = students_df[(students_df.GRADE <= 5) | (students_df.GRADE == 13)]\n",
    "ms_students_df = students_df[(students_df.GRADE >= 6) & (students_df.GRADE <= 8)]\n",
    "hs_students_df = students_df[(students_df.GRADE >= 9) & (students_df.GRADE <= 12)]\n",
    "\n",
    "def group_students_by_spa(student):\n",
    "    \"\"\"GroupBy function for gathering student records to their SPAs.\n",
    "    \n",
    "    Args:\n",
    "        student: integer row index of the student record\n",
    "    \n",
    "    Returns:\n",
    "        A label to group this record into (the student's SPA).\n",
    "    \"\"\"\n",
    "    spa_index = spas_df.geometry.map(lambda spa: spa.contains(students_df.loc[student].geometry))\n",
    "    spa_index = spa_index[spa_index == True]\n",
    "    if len(spa_index) == 0:\n",
    "        return \"NONE\"\n",
    "    assert(len(spa_index) == 1)\n",
    "    return spas_df.loc[spa_index.index[0]].STDYAREA\n",
    "\n",
    "groups_path = \"data/spa_groups.json\"\n",
    "if os.path.exists(groups_path):\n",
    "    with open(groups_path, \"r\") as fp:\n",
    "        spa_groups = json.load(fp)\n",
    "else:\n",
    "    # This is O(k * n) overall for k SPAs and n students.\n",
    "    # Expect ~2.25 hours on a laptop or 1.5 on a server.\n",
    "    tic = datetime.now()\n",
    "    spa_groups = students_df.groupby(by=group_students_by_spa).groups\n",
    "    toc = datetime.now()\n",
    "    print(toc - tic)\n",
    "\n",
    "    def serialize_groups(obj):\n",
    "        if isinstance(obj, pd.Int64Index):\n",
    "            return list(obj)\n",
    "        else:\n",
    "            raise Exception(\"obj was not an Int64Index as expected...\")\n",
    "\n",
    "    with open(groups_path, \"w\") as fp:\n",
    "        json.dump(spa_groups, fp, default=serialize_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This has the form of Dict[school_level: str][weight: int] = List[trial: float]\n",
    "# Utilization scores: lower is better\n",
    "utilization_scores = dict(zip(X_S, [dict() for S in X_S]))\n",
    "\n",
    "sigma = 5\n",
    "for school_level in X_S:\n",
    "    for weight in weights:\n",
    "        final_partitions = [shc_results[school_level][weight][str(trial)][\"info\"][\"Final\"][\"zones\"] for trial in range(1, 26)]\n",
    "        trial_utilizations = []\n",
    "\n",
    "        for i, trial in enumerate(final_partitions, start=1):\n",
    "            utilization = 0\n",
    "            for school, school_district in trial.items():\n",
    "                school_population = school_district[\"Population\"]\n",
    "                school_capacity = school_district[\"Capacity\"]\n",
    "                utilization += abs(math.atan(sigma * (1 - school_population / school_capacity)))\n",
    "            utilization /= ((math.pi / 2) * len(trial.keys()))\n",
    "            assert(utilization >= 0 and utilization <= 1)\n",
    "            trial_utilizations.append(utilization) \n",
    "        utilization_scores[school_level][weight] = trial_utilizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:21.144391\n"
     ]
    }
   ],
   "source": [
    "# Socioeconomic scores: lower is better\n",
    "socioeconomic_scores = dict(zip(X_S, [dict() for S in X_S]))\n",
    "\n",
    "# FSI value of 1 or 2 indicates free/reduced meals.\n",
    "county_farm_rate = dict()\n",
    "county_farm_rate[\"ES\"] = len(es_students_df[es_students_df.FSI <= 2]) / len(es_students_df)\n",
    "county_farm_rate[\"MS\"] = len(ms_students_df[ms_students_df.FSI <= 2]) / len(ms_students_df)\n",
    "county_farm_rate[\"HS\"] = len(hs_students_df[hs_students_df.FSI <= 2]) / len(hs_students_df)\n",
    "\n",
    "def count_school_farms(spa_name, school_level):\n",
    "    try:\n",
    "        spa_students = students_df.loc[spa_groups[spa_name]]\n",
    "    except:\n",
    "        spa = spas_df[spas_df.STDYAREA == spa_name].iloc[0]\n",
    "        assert spa.TOTAL_KG_5 + spa.TOTAL_6_8 + spa.TOTAL_9_12 == 0\n",
    "        return 0\n",
    "    if school_level == \"ES\":\n",
    "        spa_students = spa_students[(spa_students.GRADE <= 5) | (spa_students.GRADE == 13)]\n",
    "    elif school_level == \"MS\":\n",
    "        spa_students = spa_students[(spa_students.GRADE >= 6) & (spa_students.GRADE <= 8)]\n",
    "    elif school_level == \"HS\":\n",
    "        spa_students = spa_students[(spa_students.GRADE >= 9) & (spa_students.GRADE <= 12)]\n",
    "    return len(spa_students[spa_students.FSI <= 2])\n",
    "\n",
    "normalization = dict()\n",
    "for level in X_S:\n",
    "    normalization[level] = max([1 - county_farm_rate[level], county_farm_rate[level]])\n",
    "\n",
    "# Expect ~38 minutes.\n",
    "tic = datetime.now()\n",
    "for school_level in X_S:\n",
    "    for weight in weights:\n",
    "        final_partitions = [shc_results[school_level][weight][str(trial)][\"info\"][\"Final\"][\"zones\"] for trial in range(1, 26)]\n",
    "        trial_economic = []\n",
    "\n",
    "        for i, trial in enumerate(final_partitions, start=1):\n",
    "            economic = 0\n",
    "            for school, school_district in trial.items():\n",
    "                school_farm_students = sum([count_school_farms(spa, school_level) for spa in school_district[\"STATE\"]])\n",
    "                if school_district[\"Population\"] == 0:\n",
    "                    # There are some strange plans where nobody was assigned to a school...\n",
    "                    economic += county_farm_rate[school_level]\n",
    "                else:\n",
    "                    economic += abs(school_farm_students / school_district[\"Population\"] - county_farm_rate[school_level]) / normalization[level]\n",
    "            economic /= len(trial.keys())\n",
    "            assert economic >= 0 and economic <= 1, economic\n",
    "            trial_economic.append(economic)\n",
    "        socioeconomic_scores[school_level][weight] = trial_economic\n",
    "toc = datetime.now()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffchan/.vre/36/lib/python3.6/site-packages/ipykernel_launcher.py:42: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:43:51.289229\n"
     ]
    }
   ],
   "source": [
    "# Diversity scores: lower is better\n",
    "diversity_scores = dict(zip(X_S, [dict() for S in X_S]))\n",
    "\n",
    "county_entropy = dict()\n",
    "county_entropy[\"ES\"] = es_students_df.ETHNIC.value_counts() / len(es_students_df)\n",
    "county_entropy[\"ES\"] = county_entropy[\"ES\"].apply(lambda value: value * np.log(1 / value)).sum()\n",
    "county_entropy[\"MS\"] = ms_students_df.ETHNIC.value_counts() / len(ms_students_df)\n",
    "county_entropy[\"MS\"] = county_entropy[\"MS\"].apply(lambda value: value * np.log(1 / value)).sum()\n",
    "county_entropy[\"HS\"] = hs_students_df.ETHNIC.value_counts() / len(hs_students_df)\n",
    "county_entropy[\"HS\"] = county_entropy[\"HS\"].apply(lambda value: value * np.log(1 / value)).sum()\n",
    "\n",
    "county_pop = {\"ES\": len(es_students_df), \"MS\": len(ms_students_df), \"HS\": len(hs_students_df)}\n",
    "\n",
    "def query_ethnicity_column(spa_name, school_level):\n",
    "    try:\n",
    "        spa_students = students_df.loc[spa_groups[spa_name]]\n",
    "    except:\n",
    "        spa = spas_df[spas_df.STDYAREA == spa_name].iloc[0]\n",
    "        assert spa.TOTAL_KG_5 + spa.TOTAL_6_8 + spa.TOTAL_9_12 == 0\n",
    "        return pd.Series(np.zeros(7), index=students_df.ETHNIC.unique(), name=\"ETHNIC\")\n",
    "    if school_level == \"ES\":\n",
    "        spa_students = spa_students[(spa_students.GRADE <= 5) | (spa_students.GRADE == 13)]\n",
    "    elif school_level == \"MS\":\n",
    "        spa_students = spa_students[(spa_students.GRADE >= 6) & (spa_students.GRADE <= 8)]\n",
    "    elif school_level == \"HS\":\n",
    "        spa_students = spa_students[(spa_students.GRADE >= 9) & (spa_students.GRADE <= 12)]\n",
    "    return spa_students.ETHNIC.value_counts()\n",
    "\n",
    "# Expect ~45 minutes.\n",
    "tic = datetime.now()\n",
    "for school_level in X_S:\n",
    "    for weight in weights:\n",
    "        final_partitions = [shc_results[school_level][weight][str(trial)][\"info\"][\"Final\"][\"zones\"] for trial in range(1, 26)]\n",
    "        trial_diversity = []\n",
    "\n",
    "        for i, trial in enumerate(final_partitions, start=1):\n",
    "            diversity = 0\n",
    "            for school, school_district in trial.items():\n",
    "                spa_list = pd.DataFrame()\n",
    "                for spa in school_district[\"STATE\"]:\n",
    "                    counts = query_ethnicity_column(spa, school_level)\n",
    "                    spa_list = pd.concat([spa_list, counts.to_frame().T])\n",
    "\n",
    "                entropy = spa_list.sum(axis=0)\n",
    "                if school_district[\"Population\"] == 0:\n",
    "                    continue\n",
    "                entropy = entropy / school_district[\"Population\"]\n",
    "                def calc_entropy(value):\n",
    "                    if value == 0 or np.isnan(value):\n",
    "                        return 0\n",
    "                    return value * np.log(1 / value)\n",
    "                entropy = entropy.apply(calc_entropy).sum()\n",
    "\n",
    "                diversity += (school_district[\"Population\"] * (county_entropy[school_level] - entropy)) / (county_entropy[school_level] * county_pop[school_level])\n",
    "\n",
    "            assert diversity >= 0 and diversity <= 1, \"%s, %s\" % (str(diversity), school_district[\"Population\"])\n",
    "            trial_diversity.append(diversity)\n",
    "        diversity_scores[school_level][weight] = trial_diversity\n",
    "toc = datetime.now()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute walkability, we need to compute a distance matrix:\n",
    "# This lookup table will tell us the distances of every student to every school.\n",
    "# This will in turn be used to compute the number of students within walking distance of their nearest school.\n",
    "\n",
    "# Due to numerical stability, the Haversine Formula is needed for GPS distances <= 1 km.\n",
    "# We don't need to worry about antipodal instabilities in the traditional formulation.\n",
    "# The haversine package most likely makes assumptions about the ellipsoid CRS.\n",
    "# (I.e. they probably use a static radius of the earth, losing precision with the GIS CRS.)\n",
    "# This should be sufficiently accurate for now.  \n",
    "# # TODO: improve precision if necessary\n",
    "\n",
    "# Get this data in miles.\n",
    "es_students_coords = list(es_students_df.geometry.map(lambda point: point.coords[0]))\n",
    "es_schools_coords = list(es_schools_df.geometry.map(lambda point: point.coords[0]))\n",
    "es_distance = pd.DataFrame(haversine_vector(es_students_coords, es_schools_coords, Unit.MILES, comb=True).transpose(), index=es_students_df.index, columns=es_schools_df.SCH_CODE)\n",
    "\n",
    "ms_students_coords = list(ms_students_df.geometry.map(lambda point: point.coords[0]))\n",
    "ms_schools_coords = list(ms_schools_df.geometry.map(lambda point: point.coords[0]))\n",
    "ms_distance = pd.DataFrame(haversine_vector(ms_students_coords, ms_schools_coords, Unit.MILES, comb=True).transpose(), index=ms_students_df.index, columns=ms_schools_df.SCH_CODE)\n",
    "\n",
    "hs_students_coords = list(hs_students_df.geometry.map(lambda point: point.coords[0]))\n",
    "hs_schools_coords = list(hs_schools_df.geometry.map(lambda point: point.coords[0]))\n",
    "hs_distance = pd.DataFrame(haversine_vector(hs_students_coords, hs_schools_coords, Unit.MILES, comb=True).transpose(), index=hs_students_df.index, columns=hs_schools_df.SCH_CODE)\n",
    "\n",
    "walkable_distance = {\"ES\": 1, \"MS\": 1.25, \"HS\": 1.25}\n",
    "es_walkable = (es_distance.min(axis=1) <= walkable_distance[\"ES\"]).value_counts()[True]\n",
    "ms_walkable = (ms_distance.min(axis=1) <= walkable_distance[\"MS\"]).value_counts()[True]\n",
    "hs_walkable = (hs_distance.min(axis=1) <= walkable_distance[\"HS\"]).value_counts()[True]\n",
    "county_walkable = {\"ES\": es_walkable, \"MS\": ms_walkable, \"HS\": hs_walkable}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:02.330060\n"
     ]
    }
   ],
   "source": [
    "walkability_scores = dict(zip(X_S, [dict() for S in X_S]))\n",
    "students = {\"ES\": es_students_df, \"MS\": ms_students_df, \"HS\": hs_students_df}\n",
    "distances = {\"ES\": es_distance, \"MS\": ms_distance, \"HS\": hs_distance}\n",
    "\n",
    "tic = datetime.now()\n",
    "for school_level in X_S:\n",
    "    for weight in weights:\n",
    "        final_partitions = [shc_results[school_level][weight][str(trial)][\"info\"][\"Final\"][\"zones\"] for trial in range(1, 26)]\n",
    "        trial_walkability = []\n",
    "\n",
    "        for i, trial in enumerate(final_partitions, start=1):\n",
    "            students_in_walking_distance = 0\n",
    "            for school, school_district in trial.items():\n",
    "                student_indices = np.concatenate([(np.array(spa_groups[spa_name], dtype=np.int32) if spa_name in spa_groups else np.array([])) for spa_name in school_district[\"STATE\"]])\n",
    "                assert len(student_indices.shape) == 1\n",
    "                student_indices = students[school_level].index.isin(student_indices)\n",
    "                \n",
    "                distance_from_school = (distances[school_level].loc[student_indices])[school]\n",
    "\n",
    "                in_distance = (distance_from_school <= walkable_distance[school_level])\n",
    "                if in_distance.any():\n",
    "                    students_in_walking_distance += in_distance.value_counts()[True]\n",
    "                \n",
    "            walkability = 1 - students_in_walking_distance / county_walkable[school_level]\n",
    "            assert(walkability >= 0 and walkability <= 1)\n",
    "            trial_walkability.append(walkability) \n",
    "        walkability_scores[school_level][weight] = trial_walkability\n",
    "toc = datetime.now()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffchan/.vre/36/lib/python3.6/site-packages/ipykernel_launcher.py:41: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We would like baseline statistics to compare these results to.\n",
    "# How well do these heuristics do against the existing school zones?\n",
    "schools = {\"ES\": es_schools_df, \"MS\": ms_schools_df, \"HS\": hs_schools_df}\n",
    "\n",
    "existing_plan = dict()\n",
    "for level in X_S:\n",
    "    existing_plan[level] = shc_results[level][7][\"1\"][\"info\"][\"Final\"][\"zones\"]\n",
    "\n",
    "utilization_baseline = dict()\n",
    "for level in X_S:\n",
    "    utilization = 0\n",
    "    for school, zone in existing_plan[level].items():\n",
    "        school_population = zone[\"Population\"]\n",
    "        school_capacity = zone[\"Capacity\"]\n",
    "        utilization += abs(math.atan(sigma * (1 - school_population / school_capacity)))\n",
    "    utilization /= ((math.pi / 2) * len(schools[level]))\n",
    "    assert utilization >= 0 and utilization <= 1\n",
    "    utilization_baseline[level] = utilization\n",
    "\n",
    "socioeconomic_baseline = dict()\n",
    "for level in X_S:\n",
    "    economic = 0\n",
    "    for school, zone in existing_plan[level].items():\n",
    "        school_farm_students = sum([count_school_farms(spa, school_level) for spa in zone[\"STATE\"]])\n",
    "        if zone[\"Population\"] == 0:\n",
    "            # There are some strange plans where nobody was assigned to a school...\n",
    "            economic += county_farm_rate[level]\n",
    "        else:\n",
    "            economic += abs(school_farm_students / zone[\"Population\"] - county_farm_rate[level]) / normalization[level]\n",
    "    economic /= len(schools[level])\n",
    "    assert economic >= 0 and economic <= 1, economic\n",
    "    socioeconomic_baseline[level] = economic\n",
    "\n",
    "diversity_baseline = dict()\n",
    "for level in X_S:\n",
    "    diversity = 0\n",
    "    for school, zone in existing_plan[level].items():\n",
    "        spa_list = pd.DataFrame()\n",
    "        for spa in zone[\"STATE\"]:\n",
    "            counts = query_ethnicity_column(spa, level)\n",
    "            spa_list = pd.concat([spa_list, counts.to_frame().T])\n",
    "\n",
    "        entropy = spa_list.sum(axis=0)\n",
    "        if zone[\"Population\"] == 0:\n",
    "            continue\n",
    "        entropy = entropy / zone[\"Population\"]\n",
    "        def calc_entropy(value):\n",
    "            if value == 0 or np.isnan(value):\n",
    "                return 0\n",
    "            return value * np.log(1 / value)\n",
    "        entropy = entropy.apply(calc_entropy).sum()\n",
    "\n",
    "        diversity += (zone[\"Population\"] * (county_entropy[level] - entropy)) / (county_entropy[level] * county_pop[level])\n",
    "\n",
    "    assert diversity >= 0 and diversity <= 1, \"%s, %s\" % (str(diversity), zone[\"Population\"])\n",
    "    diversity_baseline[level] = diversity\n",
    "\n",
    "walkability_baseline = dict()\n",
    "for level in X_S:\n",
    "    students_in_walking_distance = 0\n",
    "    for school, zone in existing_plan[level].items():\n",
    "        student_indices = np.concatenate([(np.array(spa_groups[spa_name], dtype=np.int32) if spa_name in spa_groups else np.array([])) for spa_name in zone[\"STATE\"]])\n",
    "        assert len(student_indices.shape) == 1\n",
    "        student_indices = students[level].index.isin(student_indices)\n",
    "        \n",
    "        distance_from_school = (distances[level].loc[student_indices])[school]\n",
    "\n",
    "        in_distance = (distance_from_school <= walkable_distance[level])\n",
    "        if in_distance.any():\n",
    "            students_in_walking_distance += in_distance.value_counts()[True]\n",
    "        \n",
    "    walkability = 1 - students_in_walking_distance / county_walkable[level]\n",
    "    assert walkability >= 0 and walkability <= 1\n",
    "    walkability_baseline[level] = walkability\n",
    "\n",
    "baseline_scores = {\"utilization\": utilization_baseline, \"socioeconomic\": socioeconomic_baseline, \"diversity\": diversity_baseline, \"walkability\": walkability_baseline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_scores/utilization_scores.pkl\n",
      "metric_scores/socioeconomic_scores.pkl\n",
      "metric_scores/diversity_scores.pkl\n",
      "metric_scores/walkability_scores.pkl\n",
      "metric_scores/baseline_scores.pkl\n"
     ]
    }
   ],
   "source": [
    "DIR = 'metric_scores/'\n",
    "if os.path.exists(DIR) == False:\n",
    "    os.makedirs(DIR)\n",
    "metrics = ['utilization_scores', 'socioeconomic_scores', 'diversity_scores', 'walkability_scores', 'baseline_scores']\n",
    "for m in metrics:\n",
    "    saved_PATH = \"{}{}.pkl\".format(DIR, m)\n",
    "    with open(saved_PATH, 'wb') as f:\n",
    "        print(saved_PATH)\n",
    "        pkl.dump(locals()[m], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
